{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fr-005.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "OyO3Z_jVZ8OI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# Import TensorFlow >= 1.10 and enable eager execution\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XZtsgr3GaR2M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install sk-video"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MX9yIf-9cuJ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import data and load it in \n",
        "\n",
        "from glob import glob\n",
        "\n",
        "how_does_that_sound_15 = glob('drive/My Drive/data-fr-005/how does that sound/15*.mp4')\n",
        "# how_does_that_sound_1f = glob('drive/My Drive/data-fr-005/how does that sound/1f*.mp4')\n",
        "\n",
        "how_does_that_sound = how_does_that_sound_15 \n",
        "\n",
        "that_sounds_great_15 = glob('drive/My Drive/data-fr-005/that sounds great/15*.mp4')\n",
        "# that_sounds_great_1f = glob('drive/My Drive/data-fr-005/that sounds great/1f*.mp4')\n",
        "\n",
        "that_sounds_great = that_sounds_great_15\n",
        "\n",
        "print(len(how_does_that_sound))\n",
        "print(len(that_sounds_great))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zdlTpoKCgjGL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = []\n",
        "y = []\n",
        "\n",
        "import skvideo.io  \n",
        " \n",
        "for i,vid in enumerate(that_sounds_great):\n",
        "#   x.append(skvideo.io.vread(vid,outputdict={'-r': '15'}, num_frames=75))\n",
        "  x.append(tf.to_float(skvideo.io.vread(vid,outputdict={'-r': '15'}, num_frames=75)))\n",
        "  y.append([0, 3, 5, 6, 8, 8, 8, 1])\n",
        "  if i % 10 == 0:\n",
        "    print(i)\n",
        "  \n",
        "for i,vid in enumerate(how_does_that_sound):\n",
        "  x.append(tf.to_float(skvideo.io.vread(vid,outputdict={'-r': '15'}, num_frames=75))) \n",
        "#   x.append(skvideo.io.vread(vid,outputdict={'-r': '15'}, num_frames=75))\n",
        "  y.append([0, 7, 2, 3, 4, 8, 8, 1])\n",
        "  if i % 10 == 0:\n",
        "    print(i)\n",
        "\n",
        "# print(np.asarray(x).shape)\n",
        "# print(np.asarray(x2).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8UF09yWbDmx4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(x), len(y), x[0].shape\n",
        "# x.nbytes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NClI-2J-apno",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.imshow(x[1][1])\n",
        "plt.colorbar()\n",
        "plt.grid(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NF2p1DEpmB46",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_tensor = x\n",
        "input_max_len = 75\n",
        "\n",
        "target_tensor = np.asarray(y).astype(np.int32)\n",
        "output_max_len = 8\n",
        "output_vocab = 9\n",
        "\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WicPk2d-j2Cd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input_tensor_train[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rHACbC7coNU2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input_tensor_train = tf.to_float(input_tensor_train)\n",
        "# target_tensor_train = target_tensor_train.astype(np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mzHp_5Z9kPMH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# BUFFER_SIZE = len(input_tensor_train)\n",
        "\n",
        "BUFFER_SIZE = 64\n",
        "BATCH_SIZE = 2\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "\n",
        "embedding_dim = 16\n",
        "units = 16\n",
        "\n",
        "vocab_tar_size = output_vocab\n",
        "\n",
        "# dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train))\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TM6JXb816n0f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i,j in dataset.take(2):\n",
        "  print (j)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SzpH8tefspsL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gru(units):\n",
        "  # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n",
        "  # the code automatically does that.\n",
        "  if tf.test.is_gpu_available():\n",
        "    print('CuDNNGRU')\n",
        "    return tf.keras.layers.CuDNNGRU(units, \n",
        "                                    return_sequences=True, \n",
        "                                    return_state=True, \n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        " \n",
        "  else:\n",
        "    print('GRU')\n",
        "    return tf.layers.bidirectional(tf.keras.layers.GRU(units, \n",
        "                               return_sequences=True, \n",
        "                               return_state=True, \n",
        "                               recurrent_activation='sigmoid', \n",
        "                               recurrent_initializer='glorot_uniform'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kmZ7RIh1sqn9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(1000, embedding_dim)\n",
        "        \n",
        "        self.zero1 = tf.keras.layers.ZeroPadding3D(padding=(1, 2, 2), name='zero1')\n",
        "        self.conv1 = tf.keras.layers.Conv3D(32, (3, 5, 5), strides=(1, 2, 2), kernel_initializer = tf.keras.initializers.he_normal(seed=None), name='conv1')\n",
        "        self.batc1 = tf.keras.layers.BatchNormalization(name='batc1')\n",
        "        self.actv1 = tf.keras.layers.Activation('relu', name='actv1')\n",
        "        self.drop1 = tf.keras.layers.SpatialDropout3D(0.5)\n",
        "        self.maxp1 = tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max1')\n",
        " \n",
        "        \n",
        "        self.zero2 = tf.keras.layers.ZeroPadding3D(padding=(1, 2, 2), name='zero2')\n",
        "        self.conv2 = tf.keras.layers.Conv3D(64, (3, 5, 5), strides=(1, 1, 1), kernel_initializer = tf.keras.initializers.he_normal(seed=None), name='conv2')\n",
        "        self.batc2 = tf.keras.layers.BatchNormalization(name='batc2')\n",
        "        self.actv2 = tf.keras.layers.Activation('relu', name='actv2')\n",
        "        self.drop2 = tf.keras.layers.SpatialDropout3D(0.5)\n",
        "        self.maxp2 = tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max2')\n",
        "\n",
        "        self.zero3 = tf.keras.layers.ZeroPadding3D(padding=(1, 1, 1), name='zero3')\n",
        "        self.conv3 = tf.keras.layers.Conv3D(96, (3, 3, 3), strides=(1, 1, 1), kernel_initializer=tf.keras.initializers.he_normal(seed=None), name='conv3')\n",
        "        self.batc3 = tf.keras.layers.BatchNormalization(name='batc3')\n",
        "        self.actv3 = tf.keras.layers.Activation('relu', name='actv3')\n",
        "        self.drop3 = tf.keras.layers.SpatialDropout3D(0.5)\n",
        "        self.maxp3 = tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max3')\n",
        "        \n",
        "        self.zero4 = tf.keras.layers.ZeroPadding3D(padding=(1, 1, 1), name='zero4')\n",
        "        self.conv4 = tf.keras.layers.Conv3D(128, (3, 3, 3), strides=(1, 1, 1), kernel_initializer=tf.keras.initializers.he_normal(seed=None), name='conv3')\n",
        "        self.batc4 = tf.keras.layers.BatchNormalization(name='batc4')\n",
        "        self.actv4 = tf.keras.layers.Activation('relu', name='actv4')\n",
        "        self.drop4 = tf.keras.layers.SpatialDropout3D(0.5)\n",
        "        self.maxp4 = tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max4')\n",
        "        \n",
        "        self.resh1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())\n",
        "        \n",
        "        self.gru = gru(self.enc_units)\n",
        "        \n",
        "    def call(self, x, hidden):\n",
        "        print(x.shape)\n",
        "#         x = self.embedding(x)\n",
        "       \n",
        "        x = self.zero1(x)\n",
        "#         print(x.shape)\n",
        "        x = self.conv1(x)\n",
        "#         print(x.shape)\n",
        "        x = self.batc1(x)\n",
        "        x = self.actv1(x)\n",
        "        x = self.drop1(x)\n",
        "        x = self.maxp1(x)\n",
        "        \n",
        "        print('conv1: '+str(x.shape))\n",
        "        x = self.zero2(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.batc2(x)\n",
        "        x = self.actv2(x)\n",
        "        x = self.drop2(x)\n",
        "        x = self.maxp2(x)\n",
        "        \n",
        "        print('conv2: '+str(x.shape))\n",
        "        x = self.zero3(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.batc3(x)\n",
        "        x = self.actv3(x)\n",
        "        x = self.drop3(x)\n",
        "        x = self.maxp3(x)\n",
        "        \n",
        "#         x = self.zero4(x)\n",
        "#         x = self.conv4(x)\n",
        "#         x = self.batc4(x)\n",
        "#         x = self.actv4(x)\n",
        "#         x = self.drop4(x)\n",
        "#         x = self.maxp4(x)\n",
        "\n",
        "#         print(str('in_resh: ')+str(x.shape))\n",
        "#         print(x.shape)      \n",
        "#         x = self.resh1(x)   -- causing error?\n",
        "#         x = x.reshape(*x.shape[:1], -1)\n",
        "        x = tf.reshape(x, [*x.shape[:1], -1])\n",
        "\n",
        "        print(str('in_embedd: ')+str(x.shape))\n",
        "        x = self.embedding(x)\n",
        "    \n",
        "#         print(str('in_gru: ')+str(x.shape))\n",
        "        \n",
        "        output, state = self.gru(x, initial_state = hidden)        \n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EUKV4Xo2stQ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.dec_units)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "        # used for attention\n",
        "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        \n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        \n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
        "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
        "        \n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        \n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        \n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        \n",
        "        # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x)\n",
        "        \n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        \n",
        "        # output shape == (batch_size * 1, vocab)\n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, state, attention_weights\n",
        "        \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DpiXIqjbs0Wr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder = Encoder(embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
        "\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = 1 - np.equal(real, 0)\n",
        "  loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
        "  return tf.reduce_mean(loss_)\n",
        "\n",
        "\n",
        "checkpoint_prefix = 'drive/My Drive/data-fr-005/ckpt1/'\n",
        "# checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JruGjhPVs1rI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for (batch, (inp, targ)) in enumerate(dataset):\n",
        "        loss = 0\n",
        "        \n",
        "#         print(str('inp: ')+str(inp.shape))\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "            enc_output, enc_hidden = encoder(inp, hidden)\n",
        "            \n",
        "            dec_hidden = enc_hidden\n",
        "            \n",
        "#             print('hidden: '+str(enc_hidden))\n",
        "#             print('out: '+str(enc_output))\n",
        "\n",
        "            dec_input = tf.expand_dims([0] * BATCH_SIZE, 1)   \n",
        "            \n",
        "#             print(dec_input)\n",
        "            \n",
        "            # Teacher forcing - feeding the target as the next input\n",
        "            for t in range(1, targ.shape[1]):\n",
        "                # passing enc_output to the decoder\n",
        "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "               \n",
        "#                 print('\\ntarg[:, t: ' + str(targ[:, t]))\n",
        "#                 print('predictions: ' + str(predictions))\n",
        "                loss += loss_function(targ[:, t], predictions)\n",
        "                \n",
        "          \n",
        "                # using teacher forcing\n",
        "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "        \n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "        \n",
        "#         print(str('batch loss: ') + str(batch_loss))\n",
        "\n",
        "        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        variables = encoder.variables + decoder.variables\n",
        "        \n",
        "#         print(encoder.variables[0].shape)\n",
        "#         print(decoder.variables[0].shape)\n",
        "#         print(variables[0].shape)\n",
        "#         print(len(decoder.variables))\n",
        "#         print(len(encoder.variables))\n",
        "      \n",
        "        gradients = tape.gradient(loss, variables, output_gradients=None)\n",
        "            \n",
        "        optimizer.apply_gradients(zip(gradients, variables))\n",
        "        \n",
        "        if batch % 2 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.numpy()))\n",
        "    # saving (checkpoint) the model every 2 epochs\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                        total_loss / N_BATCH))\n",
        "    print('Time taken for epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X7D_NNhtveNM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# obj0, obj1, obj2 are created here...\n",
        "\n",
        "# Saving the objects:\n",
        "with open('objs.pkl', 'w') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([encoder, decoder], f)\n",
        "\n",
        "# Getting back the objects:\n",
        "# with open('objs.pkl') as f:  # Python 3: open(..., 'rb')\n",
        "#     obj0, obj1, obj2 = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XpS9ZMCu40EF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input_tensor_val = tf.to_float(input_tensor_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QYFSZ-1945MR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(sentence, encoder, decoder, max_length_inp, max_length_targ):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    \n",
        "#     sentence = preprocess_sentence(sentence)\n",
        "\n",
        "#     inputs = [word2idx(vocab_en, i, 'en') for i in sentence.split(' ')]\n",
        "#     inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "#     inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    inputs = sentence\n",
        "    \n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "#     hidden = encoder.initialize_hidden_state()\n",
        "\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "    \n",
        "#     print('enc_out: '+str(enc_out))\n",
        "#     print('enc_hidden: '+str(enc_hidden))\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([0], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "        \n",
        "        # storing the attention weigths to plot later on\n",
        "#         attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "#         attention_plot[t] = attention_weights.numpy()\n",
        "        \n",
        "#         print('predictions: '+str(predictions[0]))\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        \n",
        "#         print(str('predicted ID: ')+ str(predicted_id))\n",
        "\n",
        "        result += str(predicted_id) + ' '\n",
        "\n",
        "        if predicted_id == 1:\n",
        "            return result, sentence, attention_plot\n",
        "        \n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot\n",
        "#     return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YkI7BPWe49VK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for val in range(32):\n",
        "  result, sentence, attention_plot = evaluate(tf.expand_dims(input_tensor_val[val],0), encoder, decoder, 75, 7)\n",
        "  print(str('result is: ') + str(result) + str(target_tensor_val[val]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}